{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFogWKkWzPsiDEu526Gf2A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vale150299/espd1-test/blob/main/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data organisation and how to download ERA5"
      ],
      "metadata": {
        "id": "PB_G9UzsXyDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The full ERA5 and ERA5T datasets are held in the ECMWF data archive (MARS) and a pertinent sub-set of these data, interpolated to a regular latitude/longitude grid, has been copied to the C3S Climate Data Store (CDS) disks. On the CDS disks, where most single level and pressure level parameters are available, analyses are provided rather than forecasts, unless the parameter is only available from the forecasts."
      ],
      "metadata": {
        "id": "sF6-FWxXXwDX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. This is formatted as code copy and store your API key in file $HOME/.cdsapirc. You find it at the bottom of your personal profile when you are logged in the CDS."
      ],
      "metadata": {
        "id": "8cifGLfAsnAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the content of the .cdsapirc file\n",
        "cdsapirc_content = \"\"\"\n",
        "url: https://cds.climate.copernicus.eu/api/v2\n",
        "key: 305621:c1c175cb-f45e-4395-8f13-3b3feef879d6\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to the .cdsapirc file in the home directory\n",
        "with open('/root/.cdsapirc', 'w') as file:\n",
        "    file.write(cdsapirc_content)\n"
      ],
      "metadata": {
        "id": "0LK8ekZLtbob"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code will create a file named .cdsapirc in the home directory of the Colab environment (/root/), and it will write your CDS API key information into that file.\n",
        "After running this code cell in Colab, you should have the .cdsapirc file with your API key stored in the appropriate location."
      ],
      "metadata": {
        "id": "dKUSnx5tuPYl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Install modules"
      ],
      "metadata": {
        "id": "QPEB02SEwKgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cdsapi\n",
        "!pip install xarray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23HSvcvnuahB",
        "outputId": "0a9b586e-6c94-4f28-d573-f87d6cd5b6fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdsapi\n",
            "  Downloading cdsapi-0.7.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting cads-api-client>=0.9.2 (from cdsapi)\n",
            "  Downloading cads_api_client-0.10.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from cdsapi) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from cdsapi) (4.66.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from cads-api-client>=0.9.2->cdsapi) (23.2.0)\n",
            "Collecting multiurl (from cads-api-client>=0.9.2->cdsapi)\n",
            "  Downloading multiurl-0.3.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from cads-api-client>=0.9.2->cdsapi) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->cdsapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->cdsapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->cdsapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.5.0->cdsapi) (2024.2.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from multiurl->cads-api-client>=0.9.2->cdsapi) (2023.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from multiurl->cads-api-client>=0.9.2->cdsapi) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->multiurl->cads-api-client>=0.9.2->cdsapi) (1.16.0)\n",
            "Building wheels for collected packages: multiurl\n",
            "  Building wheel for multiurl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multiurl: filename=multiurl-0.3.1-py3-none-any.whl size=21131 sha256=4876909fadd1fa4a43637825f95656a3127956191e9dccac58b99c6dcc549c04\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/d9/5f/36a39fd10d15b5b2d362ad6dc8a1bd28a3b1e14e08357944bf\n",
            "Successfully built multiurl\n",
            "Installing collected packages: multiurl, cads-api-client, cdsapi\n",
            "Successfully installed cads-api-client-0.10.0 cdsapi-0.7.0 multiurl-0.3.1\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2023.7.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from xarray) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.10/dist-packages (from xarray) (2.0.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from xarray) (24.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4->xarray) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->xarray) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Retrieve the ERA5 or ERA5T data: Use the retrieve method of the cdsapi.Client object to download the desired dataset. You will need to specify parameters such as the variable, time period, geographical extent, and resolution."
      ],
      "metadata": {
        "id": "GKNtBTtD0xNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi"
      ],
      "metadata": {
        "id": "ykZk2i5I3vYW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = cdsapi.Client()"
      ],
      "metadata": {
        "id": "ur3mxl5T3o2Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e38e27ef-9350-4137-af4f-91059dca92f9",
        "outputId": "72534748-3bc0-4fe3-dc40-326100720232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-04-29 16:20:57,687 INFO Welcome to the CDS\n",
            "INFO:cdsapi:Welcome to the CDS\n",
            "2024-04-29 16:20:57,689 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-complete\n",
            "INFO:cdsapi:Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-complete\n"
          ]
        }
      ],
      "source": [
        "c.retrieve(\"reanalysis-era5-complete\", {\n",
        "    \"class\": \"ea\",\n",
        "    \"date\": \"2023-01-01\",\n",
        "    \"expver\": \"1\",\n",
        "    \"levelist\": \"137\",\n",
        "    \"levtype\": \"ml\",\n",
        "    \"grid\": \"5.625/5.625\",\n",
        "    \"param\": \"130\",\n",
        "    \"step\": \"0\",\n",
        "    \"stream\": \"oper\",\n",
        "    \"time\": \"09:00:00\",\n",
        "    \"type\": \"an\",\n",
        "    \"format\": \"netcdf\"\n",
        "}, \"test.nc\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cdsapi\n",
        "\n",
        "c = cdsapi.Client()\n",
        "\n",
        "c.retrieve(\n",
        "    'reanalysis-era5-complete',\n",
        "    {\n",
        "        'product_type': 'reanalysis',\n",
        "        'variable': 'temperature',\n",
        "        'pressure_level': '1000',\n",
        "        'year': '2008',\n",
        "        'month': '01',\n",
        "        'day': '01',\n",
        "        'time': '12:00',\n",
        "        'format': 'netcdf',\n",
        "        'grid'          : [1.0, 1.0],       # Latitude/longitude grid.           Default: 0.25 x 0.25\n",
        "    },\n",
        "    'test1.nc')         # Output file. Adapt as you wish."
      ],
      "metadata": {
        "id": "EeiN0MIjlEWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the script, the 'grid' parameter specifies the latitude/longitude grid resolution for the data extraction. Here, it's set to [1.0, 1.0], which means that the data will be provided on a grid where each grid cell represents 1 degree of latitude by 1 degree of longitude.\n",
        "\n",
        "The default grid resolution for ERA5 data is 5.625 x 5.625 degrees. By setting 'grid': [1.0, 1.0], you are requesting a coarser grid resolution, which might result in faster data retrieval and smaller file sizes compared to using the default grid resolution."
      ],
      "metadata": {
        "id": "jbs84J2nnlTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install netcdf-bin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg_CH0wJ-bBi",
        "outputId": "913a79ac-c8e3-4b65-eb24-62a622060594"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  netcdf-bin\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 204 kB of archives.\n",
            "After this operation, 557 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netcdf-bin amd64 1:4.8.1-1 [204 kB]\n",
            "Fetched 204 kB in 2s (131 kB/s)\n",
            "Selecting previously unselected package netcdf-bin.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../netcdf-bin_1%3a4.8.1-1_amd64.deb ...\n",
            "Unpacking netcdf-bin (1:4.8.1-1) ...\n",
            "Setting up netcdf-bin (1:4.8.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# Define the command to execute\n",
        "command = ['ncdump', '-t', '-v', 'latitude,longitude,time', 'test.nc']\n",
        "\n",
        "# Execute the command and capture the output\n",
        "output = subprocess.run(command, capture_output=True, text=True)\n",
        "\n",
        "# Print the output\n",
        "print(output.stdout)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGL9NayE-Lcl",
        "outputId": "384ac1db-bd57-4d5b-f28b-bfed5f0a2801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "netcdf test {\n",
            "dimensions:\n",
            "\tlongitude = 64 ;\n",
            "\tlatitude = 33 ;\n",
            "\ttime = 6 ;\n",
            "variables:\n",
            "\tfloat longitude(longitude) ;\n",
            "\t\tlongitude:units = \"degrees_east\" ;\n",
            "\t\tlongitude:long_name = \"longitude\" ;\n",
            "\tfloat latitude(latitude) ;\n",
            "\t\tlatitude:units = \"degrees_north\" ;\n",
            "\t\tlatitude:long_name = \"latitude\" ;\n",
            "\tint time(time) ;\n",
            "\t\ttime:units = \"hours since 1900-01-01 00:00:00.0\" ;\n",
            "\t\ttime:long_name = \"time\" ;\n",
            "\t\ttime:calendar = \"gregorian\" ;\n",
            "\tshort t(time, latitude, longitude) ;\n",
            "\t\tt:scale_factor = 0.00121173244814695 ;\n",
            "\t\tt:add_offset = 271.325176909655 ;\n",
            "\t\tt:_FillValue = -32767s ;\n",
            "\t\tt:missing_value = -32767s ;\n",
            "\t\tt:units = \"K\" ;\n",
            "\t\tt:long_name = \"Temperature\" ;\n",
            "\t\tt:standard_name = \"air_temperature\" ;\n",
            "\n",
            "// global attributes:\n",
            "\t\t:Conventions = \"CF-1.6\" ;\n",
            "\t\t:history = \"2024-04-25 08:51:50 GMT by grib_to_netcdf-2.28.1: /opt/ecmwf/mars-client/bin/grib_to_netcdf -S param -o /cache/data6/adaptor.mars.external-1714035110.1544075-23233-5-bf6524c3-9bdc-4900-82a4-bbf4f80543a3.nc /cache/tmp/bf6524c3-9bdc-4900-82a4-bbf4f80543a3-adaptor.mars.external-1714035109.0302331-23233-7-tmp.grib\" ;\n",
            "data:\n",
            "\n",
            " longitude = 0, 5.625, 11.25, 16.875, 22.5, 28.125, 33.75, 39.375, 45, \n",
            "    50.625, 56.25, 61.875, 67.5, 73.125, 78.75, 84.375, 90, 95.625, 101.25, \n",
            "    106.875, 112.5, 118.125, 123.75, 129.375, 135, 140.625, 146.25, 151.875, \n",
            "    157.5, 163.125, 168.75, 174.375, 180, 185.625, 191.25, 196.875, 202.5, \n",
            "    208.125, 213.75, 219.375, 225, 230.625, 236.25, 241.875, 247.5, 253.125, \n",
            "    258.75, 264.375, 270, 275.625, 281.25, 286.875, 292.5, 298.125, 303.75, \n",
            "    309.375, 315, 320.625, 326.25, 331.875, 337.5, 343.125, 348.75, 354.375 ;\n",
            "\n",
            " latitude = 90, 84.375, 78.75, 73.125, 67.5, 61.875, 56.25, 50.625, 45, \n",
            "    39.375, 33.75, 28.125, 22.5, 16.875, 11.25, 5.625, 0, -5.625, -11.25, \n",
            "    -16.875, -22.5, -28.125, -33.75, -39.375, -45, -50.625, -56.25, -61.875, \n",
            "    -67.5, -73.125, -78.75, -84.375, -90 ;\n",
            "\n",
            " time = \"2023-01-01 09\", \"2023-01-01 21\", \"2023-01-02 09\", \"2023-01-02 21\", \n",
            "    \"2023-01-03 09\", \"2023-01-03 21\" ;\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output you provided is the metadata summary of the NetCDF file test.nc. It describes the dimensions, variables, and attributes contained within the file.\n",
        "\n",
        "Here's a breakdown of the information:\n",
        "\n",
        "Dimensions:\n",
        "- longitude: 64 data points\n",
        "- latitude: 33 data points\n",
        "- time: 6 data points\n",
        "Variables:\n",
        "- longitude: Array of longitude values with units in degrees east.\n",
        "- latitude: Array of latitude values with units in degrees north.\n",
        "- time: Array of time values representing hours since January 1, 1900, with units in hours.\n",
        "- t: 3D array representing temperature (K) with dimensions (time, latitude, longitude). It has various attributes such as scale_factor, add_offset, units, long_name, and standard_name.\n",
        "Global Attributes:\n",
        "- Conventions: CF-1.6\n",
        "- history: Information about the processing history of the file.\n",
        "Data:\n",
        "- Values for longitude, latitude, and time.\n",
        "- No data is shown for the temperature variable t in the metadata summary.\n",
        "This metadata summary provides valuable information about the structure and contents of the NetCDF file, allowing you to understand and interpret the data it contains. If you have any specific questions or tasks related to this data, feel free to ask!"
      ],
      "metadata": {
        "id": "Qud_ZeW2AZJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "\n",
        "# Open the NetCDF file\n",
        "data = xr.open_dataset('test.nc')\n",
        "\n",
        "# Access the temperature variable 't' and display its data\n",
        "temperature_data = data['t']\n",
        "print(temperature_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4l5pRmqASqg",
        "outputId": "d7528764-938f-40c5-e994-ee3d81e26888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<xarray.DataArray 't' (time: 6, latitude: 33, longitude: 64)>\n",
            "[12672 values with dtype=float32]\n",
            "Coordinates:\n",
            "  * longitude  (longitude) float32 0.0 5.625 11.25 16.88 ... 343.1 348.8 354.4\n",
            "  * latitude   (latitude) float32 90.0 84.38 78.75 73.12 ... -78.75 -84.38 -90.0\n",
            "  * time       (time) datetime64[ns] 2023-01-01T09:00:00 ... 2023-01-03T21:00:00\n",
            "Attributes:\n",
            "    units:          K\n",
            "    long_name:      Temperature\n",
            "    standard_name:  air_temperature\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows the structure and metadata of the temperature variable 't':\n",
        "\n",
        "-It's a DataArray with dimensions (time: 1, latitude: 33, longitude: 64), meaning it contains a single time step, 33 latitude points, and 64 longitude points.\n",
        "\n",
        "-The values are of type float32.\n",
        "\n",
        "-The coordinates are longitude, latitude, and time.\n",
        "\n",
        "-The time coordinate has a single value, '2023-01-01T09:00:00'.\n",
        "\n",
        "-The variable has attributes including units ('K' for Kelvin), long_name ('Temperature'), and standard_name ('air_temperature').\n",
        "\n",
        "This information gives you a comprehensive overview of the temperature data contained in the NetCDF file. If you have any further questions or need assistance with analysis or visualization, feel free to ask!"
      ],
      "metadata": {
        "id": "EQTS9p1vl-qy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The grid used in this dataset appears to be a regular grid, as indicated by the longitude and latitude coordinates.\n",
        "\n",
        "-The longitude coordinates range from 0 to 360 degrees with a spacing of approximately 5.625 degrees.\n",
        "\n",
        "-The latitude coordinates range from 90 degrees (North Pole) to -90 degrees (South Pole) with a spacing of approximately -5.625 degrees.\n",
        "\n",
        "This regular grid means that the data is evenly spaced in both longitude and latitude directions, which is common in many climate and atmospheric datasets. Each grid cell represents a specific geographic location with a uniform spacing between neighboring grid points"
      ],
      "metadata": {
        "id": "gco_PVpWmQWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the reduced grids used by ECMWF, the number of points on each latitude row is chosen so that the local east-west grid length remains approximately constant for all latitudes, with the restriction that the number should be suitable for the Fast Fourier Transform used to interpolate spectral fields to grid point fields, ie number = 2^p * 3^q * 5^r.\n",
        "\n"
      ],
      "metadata": {
        "id": "1EfyGeRHmdQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, ECMWF (European Centre for Medium-Range Weather Forecasts) and many other meteorological and climate modeling organizations often use reduced Gaussian grids or reduced latitude-longitude grids for their numerical models. These grids are designed to balance accuracy and computational efficiency.\n",
        "\n",
        "In reduced Gaussian grids:\n",
        "\n",
        "-The number of points on each latitude circle is chosen such that the distance between points remains approximately constant, ensuring a more uniform representation of the Earth's surface.\n",
        "\n",
        "-The number of grid points often follows the rules you've mentioned, where the total number of grid points is typically a product of powers of 2, 3, and 5. This choice facilitates efficient interpolation and other numerical operations, including Fast Fourier Transforms (FFTs).\n",
        "\n",
        "These grid configurations are crucial for numerical weather prediction models, climate models, and data assimilation systems used by ECMWF and other similar institutions. They allow for efficient computation while maintaining sufficient spatial resolution to capture important atmospheric features."
      ],
      "metadata": {
        "id": "zj6mei-KmlQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpolating spectral fields to grid points typically involves using spectral or Fourier methods due to their efficiency and accuracy. Here's a general approach to interpolate spectral fields to grid points:\n",
        "\n",
        "-Obtain Spectral Coefficients: Spectral fields are often represented as a series of coefficients corresponding to different spherical harmonics or wave numbers.\n",
        "\n",
        "-Inverse Transform: Use the inverse Fourier transform (or spectral transform) to convert the spectral coefficients back to grid point values. This process involves summing up contributions from different spectral components to compute the value at each grid point.\n",
        "\n",
        "-Grid Point Spacing: Ensure that the grid points are spaced appropriately based on the chosen grid system (e.g., reduced Gaussian grid or regular latitude-longitude grid).\n",
        "\n",
        "-Apply Interpolation Scheme: Apply any necessary interpolation scheme to compute the values at intermediate grid points if needed. Common interpolation methods include bilinear interpolation, bicubic interpolation, or more advanced techniques suitable for irregular grids.\n",
        "\n",
        "-Post-processing: Perform any post-processing steps as necessary, such as smoothing or filtering, to ensure the interpolated grid points meet specific requirements or constraints.\n",
        "\n",
        "The choice of interpolation method may depend on factors such as the grid configuration, computational resources, and the desired accuracy of the interpolated fields. Fast algorithms, such as those based on FFT, are often preferred for large-scale interpolation tasks due to their computational efficiency."
      ],
      "metadata": {
        "id": "lUFM_84FmtCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def interpolate_spectral_to_grid(spectral_coeffs, grid_lon, grid_lat):\n",
        "    \"\"\"\n",
        "    Interpolates spectral coefficients to grid points.\n",
        "\n",
        "    Parameters:\n",
        "        spectral_coeffs (ndarray): Array of spectral coefficients.\n",
        "        grid_lon (ndarray): Array of longitude grid points.\n",
        "        grid_lat (ndarray): Array of latitude grid points.\n",
        "\n",
        "    Returns:\n",
        "        grid_values (ndarray): Interpolated values at grid points.\n",
        "    \"\"\"\n",
        "    # Initialize grid_values array to store interpolated values\n",
        "    grid_values = np.zeros((len(grid_lat), len(grid_lon)))\n",
        "\n",
        "    # Iterate over spectral coefficients\n",
        "    for i in range(spectral_coeffs.shape[0]):\n",
        "        for j in range(spectral_coeffs.shape[1]):\n",
        "            # Compute latitude-dependent weights\n",
        "            weights_lat = np.cos(np.deg2rad(grid_lat)) * np.pi / (180.0 * len(grid_lat))\n",
        "\n",
        "            # Interpolate spectral coefficients to grid points using inverse FFT\n",
        "            grid_values += spectral_coeffs[i, j] * np.cos(i * np.pi * grid_lat / 180.0) * weights_lat\n",
        "\n",
        "    return grid_values\n",
        "\n",
        "# Example usage\n",
        "# Assuming spectral_coeffs is a 2D array of spectral coefficients,\n",
        "# grid_lon and grid_lat are 1D arrays of longitude and latitude grid points respectively\n",
        "\n",
        "# Call the interpolation function\n",
        "interpolated_grid = interpolate_spectral_to_grid(spectral_coeffs, grid_lon, grid_lat)\n",
        "\n",
        "# Now interpolated_grid contains the interpolated values at each grid point\n"
      ],
      "metadata": {
        "id": "tWNbIXvMnHEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code defines a function interpolate_spectral_to_grid that takes spectral coefficients and grid point arrays as input and returns the interpolated values at grid points using inverse Fourier transform. Note that this is a basic example, and actual implementations may involve additional considerations and optimizations based on the specific requirements of your application"
      ],
      "metadata": {
        "id": "zKPj7oy-nKpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To interpolate your temperature data from the given regular grid to a reduced Gaussian grid, you can follow these steps using xarray:\n",
        "\n",
        "-Create the Reduced Gaussian Grid: Define the reduced Gaussian grid points for latitude and longitude.\n",
        "\n",
        "-Interpolate the Data: Use xarray's interpolation capabilities to interpolate the temperature data from the regular grid to the reduced Gaussian grid."
      ],
      "metadata": {
        "id": "EyTD5AqsnLpF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xarray as xr\n",
        "import numpy as np\n",
        "\n",
        "# Open the NetCDF file\n",
        "data = xr.open_dataset('test.nc')\n",
        "\n",
        "# Define the reduced Gaussian grid points for latitude and longitude\n",
        "# Assuming you already have these arrays\n",
        "gaussian_lon = [...]  # Array of reduced Gaussian grid longitudes\n",
        "gaussian_lat = [...]  # Array of reduced Gaussian grid latitudes\n",
        "\n",
        "# Interpolate the temperature data to the reduced Gaussian grid\n",
        "interpolated_data = data['t'].interp(latitude=gaussian_lat, longitude=gaussian_lon)\n",
        "\n",
        "# Now interpolated_data contains the temperature data interpolated to the reduced Gaussian grid\n"
      ],
      "metadata": {
        "id": "C91TFerDn65D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replace [...] with your arrays of reduced Gaussian grid points. This code uses xarray's interp method to interpolate the temperature data from the regular grid to the reduced Gaussian grid based on the provided latitude and longitude coordinates.\n",
        "\n",
        "Ensure that the dimensions and coordinates of your reduced Gaussian grid match the dimensions and coordinates of the original grid. Adjust the interpolation method or perform additional processing as needed based on your specific requirements."
      ],
      "metadata": {
        "id": "yuGca5wWn_tc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reduced Gaussian grid points are typically determined based on specific rules to ensure a more uniform distribution of grid points while maintaining computational efficiency. These rules often involve selecting the number of points on each latitude circle according to a formula such as:\n",
        "\n",
        "number\n",
        "=\n",
        "2\n",
        "𝑝\n",
        "×\n",
        "3\n",
        "𝑞\n",
        "×\n",
        "5\n",
        "𝑟\n",
        "number=2\n",
        "p\n",
        " ×3\n",
        "q\n",
        " ×5\n",
        "r\n",
        "\n",
        "\n",
        "where\n",
        "𝑝\n",
        "p,\n",
        "𝑞\n",
        "q, and\n",
        "𝑟\n",
        "r are integers. The total number of grid points on the sphere is the product of these powers of 2, 3, and 5.\n",
        "\n",
        "Once you have determined the number of grid points on each latitude circle, you can compute the corresponding longitudes and latitudes."
      ],
      "metadata": {
        "id": "8CLgjh_RoBPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_gaussian_grid(num_lon, num_lat):\n",
        "    \"\"\"\n",
        "    Compute reduced Gaussian grid points.\n",
        "\n",
        "    Parameters:\n",
        "        num_lon (int): Number of grid points in longitude.\n",
        "        num_lat (int): Number of grid points in latitude.\n",
        "\n",
        "    Returns:\n",
        "        lon_points (ndarray): Array of reduced Gaussian grid longitudes.\n",
        "        lat_points (ndarray): Array of reduced Gaussian grid latitudes.\n",
        "    \"\"\"\n",
        "    # Compute the longitude grid points\n",
        "    lon_points = np.linspace(0, 360, num_lon, endpoint=False)\n",
        "\n",
        "    # Compute the latitude grid points\n",
        "    lat_points = np.zeros(num_lat)\n",
        "    for j in range(num_lat):\n",
        "        lat_points[j] = np.arcsin(2*j / (num_lat - 1) - 1) * (180 / np.pi)\n",
        "\n",
        "    return lon_points, lat_points\n",
        "\n",
        "# Example usage\n",
        "num_lon = 64  # Number of grid points in longitude\n",
        "num_lat = 33  # Number of grid points in latitude\n",
        "\n",
        "lon_points, lat_points = compute_gaussian_grid(num_lon, num_lat)\n"
      ],
      "metadata": {
        "id": "0CfOANF9oNGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function compute_gaussian_grid calculates the reduced Gaussian grid points for a given number of points in longitude (num_lon) and latitude (num_lat). You can then use these arrays of longitude and latitude points for interpolating your data onto the reduced Gaussian grid. Adjust the num_lon and num_lat parameters according to your specific requirements.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qwaRnTRgoULZ"
      }
    }
  ]
}